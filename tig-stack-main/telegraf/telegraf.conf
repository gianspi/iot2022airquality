# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply surround
# them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
# for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"


# Configuration for telegraf
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Collection offset is used to shift the collection by the given amount.
  ## This can be be used to avoid many plugins querying constraint devices
  ## at the same time by manually scheduling them in time.
  # collection_offset = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## Collected metrics are rounded to the precision specified. Precision is
  ## specified as an interval with an integer + unit (e.g. 0s, 10ms, 2us, 4s).
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  ##
  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s:
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ##
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  precision = ""

  ## Log at debug level.
  # debug = false
  ## Log only error level messages.
  # quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  logtarget = "file"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  logfile = "/var/log/telegraf/telegraf.log"

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  # logfile_rotation_interval = "0d"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # logfile_rotation_max_size = "0MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  # logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = true

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################


# Configuration for sending metrics to InfluxDB 2.0
[[outputs.influxdb_v2]]
  ## The URLs of the InfluxDB cluster nodes.
  ##
  ## Multiple URLs can be specified for a single cluster, only ONE of the
  ## urls will be written to each interval.
  ##   ex: urls = ["https://us-west-2-1.aws.cloud2.influxdata.com"]
  urls = ["http://${DOCKER_INFLUXDB_INIT_HOST}:${DOCKER_INFLUXDB_INIT_PORT}"]

  ## Token for authentication.
  token = "$DOCKER_INFLUXDB_INIT_ADMIN_TOKEN"

  ## Organization is the name of the organization you wish to write to; must exist.
  organization = "$DOCKER_INFLUXDB_INIT_ORG"

  ## Destination bucket to write into.
  bucket = "$DOCKER_INFLUXDB_INIT_BUCKET"

  ## The value of this tag will be used to determine the bucket.  If this
  ## tag is not set the 'bucket' option is used as the default.
  # bucket_tag = ""

  ## If true, the bucket tag will not be added to the metric.
  # exclude_bucket_tag = false

  ## Timeout for HTTP messages.
  # timeout = "5s"

  ## Additional HTTP headers
  # http_headers = {"X-Special-Header" = "Special-Value"}

  ## HTTP Proxy override, if unset values the standard proxy environment
  ## variables are consulted to determine which proxy, if any, should be used.
  # http_proxy = "http://corporate.proxy:3128"

  ## HTTP User-Agent
  # user_agent = "telegraf"

  ## Content-Encoding for write request body, can be set to "gzip" to
  ## compress body or "identity" to apply no encoding.
  # content_encoding = "gzip"

  ## Enable or disable uint support for writing uints influxdb 2.0.
  # influx_uint_support = false

  ## Optional TLS Config for use on HTTP connections.
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  ## Use TLS but skip chain & host verification
  insecure_skip_verify = false


###############################################################################
#                            PROCESSOR PLUGINS                                #
###############################################################################


# Run executable as long-running processor plugin
[[processors.execd]]
  # Program to run as daemon
  command = ["/usr/bin/python3", "/etc/telegraf/data_forecasting.py"]

  ## Delay before the process is restarted after an unexpected termination
  #restart_delay = "10s"


###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################


# Parse a complete file each interval
[[inputs.file]]
  ## Files to parse each interval.  Accept standard unix glob matching rules,
  ## as well as ** to match recursive files and directories.
  files = ["/etc/telegraf/provaDati.json"]

  ## Name a tag containing the name of the file the data was parsed from.  Leave empty
  ## to disable. Cautious when file name variation is high, this can increase the cardinality
  ## significantly. Read more about cardinality here:
  ## https://docs.influxdata.com/influxdb/cloud/reference/glossary/#series-cardinality
  # file_tag = ""
  #

  ## Character encoding to use when interpreting the file contents.  Invalid
  ## characters are replaced using the unicode replacement character.  When set
  ## to the empty string the data is not decoded to text.
  ##   ex: character_encoding = "utf-8"
  ##       character_encoding = "utf-16le"
  ##       character_encoding = "utf-16be"
  ##       character_encoding = ""
  # character_encoding = ""

  ## The dataformat to be read from files
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
  data_format = "json_v2"

  [[inputs.file.json_v2]]
    measurement_name = "air_quality" # A string that will become the new measurement name
    timestamp_path = "t" # A string with valid GJSON path syntax to a valid timestamp (single value)
    timestamp_format = "unix_ms" # A string with a valid timestamp format (see below for possible values)

    [[inputs.file.json_v2.object]]
      path = "@this" # A string with valid GJSON path syntax, can include array's and object's
      ## Setting optional to true will suppress errors if the configured Path doesn't match the JSON
      optional = false

      tags = ["i", "p_a", "p_o"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) to be a tag instead of a field, when adding a JSON key in this list you don't have to define it in the included_keys list
      included_keys = ["a_h", "a_t", "a_c", "q", "r", "n"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) that should be only included in result
      #excluded_keys = ["topic"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) that shouldn't be included in result
      #, "t"
      # ### Configuration to modify the resutling line protocol ###
      disable_prepend_keys = true # (or true, just not both)
      [inputs.file.json_v2.object.renames] # A map of JSON keys (for a nested key, prepend the parent keys with underscores) with a new name for the tag key
        i = "sensorID"
        p_a = "lat"
        p_o = "lon"
        a_h = "hum"
        a_t = "temp"
        a_c = "conc"
        q = "aqi"
        r = "rssi"
        n = "packet_number"
        # t = "sending_time"

      [inputs.file.json_v2.object.fields] # A map of JSON keys (for a nested key, prepend the parent keys with underscores) with a type (int,uint,float,string,bool)
        i = "string"
        p_a = "float"
        p_o = "float"
        a_h = "float"
        a_t = "float"
        a_c = "float"
        q = "float"
        r = "float"
        n = "int"


# Generic HTTP write listener
[[inputs.http_listener_v2]]
  # Address and port to host HTTP listener on
  service_address = "telegraf:8080"

  # Paths to listen to.
  paths = ["/telegraf"]

  # Save path as http_listener_v2_path tag if set to true
  path_tag = false

  # HTTP methods to accept.
  methods = ["POST"] # "PUT"

  ## maximum duration before timing out read of the request
  # read_timeout = "10s"
  ## maximum duration before timing out write of the response
  # write_timeout = "10s"

  ## Maximum allowed http request body size in bytes.
  ## 0 means to use the default of 524,288,000 bytes (500 mebibytes)
  # max_body_size = "500MB"

  # # Part of the request to consume.  Available options are "body" and "query".
  # data_source = "body"

  ## Set one or more allowed client CA certificate file names to enable mutually authenticated TLS connections
  # tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]

  ## Add service certificate and key
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"

  ## Minimal TLS version accepted by the server
  # tls_min_version = "TLS12"

  ## Optional username and password to accept for HTTP basic authentication.
  ## You probably want to make sure you have TLS configured above for this.
  # basic_username = "foobar"
  # basic_password = "barfoo"

  ## Optional setting to map http headers into tags
  ## If the http header is not present on the request, no corresponding tag will be added
  ## If multiple instances of the http header are present, only the first value will be used
  # http_header_tags = {"HTTP_HEADER" = "TAG_NAME"}

  ## Data format to consume.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
  data_format = "json_v2"

  [[inputs.http_listener_v2.json_v2]]
    measurement_name = "air_quality" # A string that will become the new measurement name
    timestamp_path = "t" # A string with valid GJSON path syntax to a valid timestamp (single value)
    timestamp_format = "unix" # A string with a valid timestamp format (see below for possible values)

    [[inputs.http_listener_v2.json_v2.object]]
      path = "@this" # A string with valid GJSON path syntax, can include array's and object's
      ## Setting optional to true will suppress errors if the configured Path doesn't match the JSON
      optional = false

      tags = ["i", "p_a", "p_o"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) to be a tag instead of a field, when adding a JSON key in this list you don't have to define it in the included_keys list
      included_keys = ["a_h", "a_t", "a_c", "q", "r", "n"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) that should be only included in result
      # excluded_keys = [] # List of JSON keys (for a nested key, prepend the parent keys with underscores) that shouldn't be included in result
      #, "t"
      # ### Configuration to modify the resutling line protocol ###
      disable_prepend_keys = true # (or true, just not both)
      [inputs.http_listener_v2.json_v2.object.renames] # A map of JSON keys (for a nested key, prepend the parent keys with underscores) with a new name for the tag key
        i = "sensorID"
        p_a = "lat"
        p_o = "lon"
        a_h = "hum"
        a_t = "temp"
        a_c = "conc"
        q = "aqi"
        r = "rssi"
        n = "packet_number"
        # t = "sending_time"

      [inputs.http_listener_v2.json_v2.object.fields] # A map of JSON keys (for a nested key, prepend the parent keys with underscores) with a type (int,uint,float,string,bool)
        i = "string"
        p_a = "float"
        p_o = "float"
        a_h = "float"
        a_t = "float"
        a_c = "float"
        q = "float"
        r = "float"
        n = "int"
        # t = "int"


# Read metrics from MQTT topic(s)
[[inputs.mqtt_consumer]]
  ## Broker URLs for the MQTT server or cluster.  To connect to multiple
  ## clusters or standalone servers, use a separate plugin instance.
  ##   example: servers = ["tcp://localhost:1883"]
  ##            servers = ["ssl://localhost:1883"]
  ##            servers = ["ws://localhost:1883"]
  servers = ["tcp://mosquitto:1883"] # PROVARE CON localhost, 192.168.0.198

  ## Topics that will be subscribed to.
  topics = [
    "sensedData",
  ]

  # The message topic will be stored in a tag specified by this value.  If set
  # to the empty string no topic tag will be created.
  topic_tag = ""

  # Username and password to connect MQTT server.
  username = "admin"
  password = "admin"

  ## The dataformat to be read from files
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
  data_format = "json_v2"

  # PROVARE COMMENTANDO QUESTA PARTE E VEDERE SE VENGONO INSERITI DATI SU INFLUX
  # POSSIBILE ANCHE CHE ARRIVI QUALCOSA DI DIVERSO DA .json (?)
  [[inputs.mqtt_consumer.json_v2]]
    measurement_name = "air_quality" # A string that will become the new measurement name
    timestamp_path = "t" # A string with valid GJSON path syntax to a valid timestamp (single value)
    timestamp_format = "unix_ms" # A string with a valid timestamp format (see below for possible values)

    [[inputs.mqtt_consumer.json_v2.object]]
      path = "@this" # A string with valid GJSON path syntax, can include array's and object's
      ## Setting optional to true will suppress errors if the configured Path doesn't match the JSON
      optional = false

      tags = ["i", "p_a", "p_o"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) to be a tag instead of a field, when adding a JSON key in this list you don't have to define it in the included_keys list
      included_keys = ["a_h", "a_t", "a_c", "q", "r", "n"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) that should be only included in result
      #excluded_keys = ["topic"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) that shouldn't be included in result
      #, "t"
      # ### Configuration to modify the resutling line protocol ###
      disable_prepend_keys = true # (or true, just not both)
      [inputs.mqtt_consumer.json_v2.object.renames] # A map of JSON keys (for a nested key, prepend the parent keys with underscores) with a new name for the tag key
        i = "sensorID"
        p_a = "lat"
        p_o = "lon"
        a_h = "hum"
        a_t = "temp"
        a_c = "conc"
        q = "aqi"
        r = "rssi"
        n = "packet_number"
        # t = "sending_time"

      [inputs.mqtt_consumer.json_v2.object.fields] # A map of JSON keys (for a nested key, prepend the parent keys with underscores) with a type (int,uint,float,string,bool)
        i = "string"
        p_a = "float"
        p_o = "float"
        a_h = "float"
        a_t = "float"
        a_c = "float"
        q = "float"
        r = "float"
        n = "int"
        # t = "int"

  ## Enable extracting tag values from MQTT topics
  ## _ denotes an ignored entry in the topic path
  # [[inputs.mqtt_consumer.topic_parsing]]
  #   topic = ""
  #   measurement = ""
  #   tags = ""
  #   fields = ""
  ## Value supported is int, float, unit
  #   [[inputs.mqtt_consumer.topic.types]]
  #      key = type





# LA CONFIGURAZIONE QUA SOTTO SERVE PER FARE IL PARSING DI DATI .json CHE HANNO LA FORMA DEI DATI PRESENTI IN provaDati.json

# ## The dataformat to be read from files
# ## Each data format has its own unique set of configuration options, read
# ## more about them here:
# ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
# data_format = "json_v2"

# [[inputs._input_.json_v2]]
#   measurement_name = "air_quality" # A string that will become the new measurement name
#   #timestamp_path = "timestamp" # A string with valid GJSON path syntax to a valid timestamp (single value)
#   #timestamp_format = "rfc3339" # A string with a valid timestamp format (see below for possible values)

#   [[inputs._input_.json_v2.object]]
#     path = "@this" # A string with valid GJSON path syntax, can include array's and object's
#     ## Setting optional to true will suppress errors if the configured Path doesn't match the JSON
#     optional = false

#     tags = ["i", "p_la", "p_lo"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) to be a tag instead of a field, when adding a JSON key in this list you don't have to define it in the included_keys list
#     included_keys = ["a_h", "a_tm", "a_co", "aq", "r"] # List of JSON keys (for a nested key, prepend the parent keys with underscores) that should be only included in result
#     # excluded_keys = [] # List of JSON keys (for a nested key, prepend the parent keys with underscores) that shouldn't be included in result
    
#     # ### Configuration to modify the resutling line protocol ###
#     disable_prepend_keys = true # (or true, just not both)
#     [inputs._input_.json_v2.object.renames] # A map of JSON keys (for a nested key, prepend the parent keys with underscores) with a new name for the tag key
#       i = "sensorID"
#       p_la = "lat"
#       p_lo = "lon"
#       a_h = "hum"
#       a_tm = "temp"
#       a_co = "conc"
#       aq = "aqi"
#       r = "rssi"

#     [inputs._input_.json_v2.object.fields] # A map of JSON keys (for a nested key, prepend the parent keys with underscores) with a type (int,uint,float,string,bool)
#       i = "string"
#       p_la = "float"
#       p_lo = "float"
#       a_h = "float"
#       a_tm = "float"
#       a_co = "float"
#       aq = "float"
#       r = "float"